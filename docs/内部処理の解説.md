# Hereticの内部処理の解説：LLMの検閲除去メカニズム

このドキュメントは、Hereticがどのように言語モデルから検閲（セーフティアライメント）を除去するかを、3つのレベルで解説します。

---

## 目次
1. [中学生レベルの解説](#中学生レベルの解説)
2. [大学生レベルの解説](#大学生レベルの解説)
3. [専門家レベルの解説](#専門家レベルの解説)

---

## 中学生レベルの解説

### Hereticは何をするツール？

Hereticは、AI言語モデルが「安全のため」に拒否するようになっている質問に答えられるようにするツールです。これを「検閲除去」と呼びます。

### なぜ検閲が必要なの？

普通のAIは、危険な質問や不適切な質問に答えないように訓練されています。例えば：
- 「悪いことをする方法を教えて」→ AIは「お答えできません」と言う
- 「普通の質問」→ AIは普通に答える

### Hereticの仕組みを簡単に説明

**1. AIの「脳」の中を調べる**
- AIの内部には「層（レイヤー）」という処理段階がたくさんあります（参照：`src/heretic/model.py` 98-104行目）
- 各層で情報が少しずつ変化していきます

**2. 「拒否する方向」を見つける**
- 良い質問（harmless）と悪い質問（harmful）をたくさん用意します（参照：`src/heretic/main.py` 122-129行目）
- それぞれの質問をAIに見せて、脳の中でどう反応するか観察します
- 「拒否する方向」= 悪い質問のときだけ強く反応する方向を計算します（参照：`src/heretic/main.py` 189-198行目）

**3. 「拒否する方向」を消す**
- AIの脳の中から、その「拒否する方向」を取り除きます（参照：`src/heretic/model.py` 161-217行目）
- これを「直交化（Orthogonalization）」と呼びます
- 数学的には、行列から特定の方向への影響を引き算で消します

**4. 最適な設定を探す**
- どのくらい強く消すか、どの層を消すかを自動で調整します（参照：`src/heretic/main.py` 206-313行目）
- 200回試行して、一番良い設定を見つけます
- 「拒否が減る」と「元のAIの性能を保つ」の両方を目指します

### たとえ話で理解しよう

Hereticは「色眼鏡を外す」ような作業です：
- AIは「安全色眼鏡」をかけていて、危険な質問が来ると「見えない！」と言います
- Hereticは脳の中を調べて、その色眼鏡がどんな色かを見つけます
- そして、その色のフィルターだけを取り除きます
- すると、AIは全ての質問が見えるようになります

### コードの参照箇所

- モデルのロード：`src/heretic/model.py` 35-83行目
- プロンプトの読み込み：`src/heretic/main.py` 122-129行目、`src/heretic/utils.py` 38-40行目
- 拒否方向の計算：`src/heretic/main.py` 189-201行目
- 直交化（検閲除去）：`src/heretic/model.py` 161-217行目
- 最適化プロセス：`src/heretic/main.py` 206-313行目

---

## 大学生レベルの解説

### 背景：Transformer言語モデルの構造

現代のLLM（Large Language Model）は、Transformerアーキテクチャに基づいています。Hereticが対象とするモデルは以下の構造を持ちます：

1. **埋め込み層（Embedding Layer）**：トークンをベクトルに変換
2. **複数のTransformer層**：各層に自己注意機構（Self-Attention）とMLP（多層パーセプトロン）
3. **出力層**：語彙上の確率分布を生成

参照：`src/heretic/model.py` 98-104行目で層の取得方法を確認

### セーフティアライメントのメカニズム

セーフティアライメントは、RLHFや他の手法で「有害な」出力を抑制するようモデルを訓練します。この結果：
- モデルの重み行列に「拒否方向（refusal direction）」が埋め込まれる
- 有害プロンプトの処理時、中間表現がこの方向に大きく投影される
- この投影が「拒否」という出力を引き起こす

### Hereticのアルゴリズム

#### ステップ1：拒否方向の特定

```
refusal_directions[l] = normalize(mean(bad_residuals[l]) - mean(good_residuals[l]))
```

参照：`src/heretic/main.py` 189-201行目

- **good_residuals**: 無害プロンプトの各層の隠れ状態（参照：`src/heretic/model.py` 273-305行目）
- **bad_residuals**: 有害プロンプトの各層の隠れ状態
- 各層で平均の差を計算し、L2正規化して方向ベクトルを得る

隠れ状態の取得（`get_residuals`メソッド）：
- 各プロンプトで1トークンだけ生成
- 各層の最後の位置の隠れ状態を抽出
- float32にアップキャストして精度を確保（参照：`src/heretic/model.py` 297行目）

#### ステップ2：方向性除去（Directional Ablation）

各層の重み行列を直交化します：

```python
projector = outer(refusal_direction, refusal_direction)  # 射影行列
matrix -= weight * (projector @ matrix)  # 直交化
```

参照：`src/heretic/model.py` 209-217行目

数学的には：
- `projector`は拒否方向への射影演算子
- `projector @ matrix`は行列の各列を拒否方向に射影
- これを元の行列から引くことで、拒否方向の成分を除去

適用される行列：
- **Attention Out-projection** (`attn.o_proj.weight`)（参照：121行目）
- **MLP Down-projection** (`mlp.down_proj.weight`)（参照：124-151行目）

#### ステップ3：パラメータ最適化

Optunaを使用したTPE（Tree-structured Parzen Estimator）による多目的最適化：

参照：`src/heretic/main.py` 305-313行目

最適化パラメータ（参照：238-270行目）：
- **direction_index**: どの層の拒否方向を使うか（または"per layer"）
- **max_weight**: 最大の除去強度（0.8-1.5）
- **max_weight_position**: 除去が最大となる層位置
- **min_weight**: 最小の除去強度
- **min_weight_distance**: 除去カーネルの幅

目的関数（参照：287行目、`evaluator.py` 57-77行目）：
1. **KL Divergence**: 元モデルとの出力分布の差（情報の保持度）
2. **Refusal Count**: 拒否応答の数（検閲除去の効果）

### LLM理論との関連

**表現工学（Representation Engineering）の観点**：
- LLMの中間表現は線形な意味空間を形成
- 特定の概念や振る舞いは、特定の方向として表現される
- これらの方向を操作することで、モデルの振る舞いを制御可能

**線形性の仮定**：
- Transformer内部の表現は高次元空間で線形構造を持つ
- "harmful"と"harmless"の差は線形分離可能
- 拒否方向は、この決定境界に直交する方向

参考文献：Arditi et al. (2024) "Refusal in Language Models Is Mediated by a Single Direction"

### コードフロー全体

1. **モデルロード**（`Model.__init__`）：`src/heretic/model.py` 35-83行目
2. **データセット読み込み**：`src/heretic/utils.py` 38-40行目
3. **バッチサイズ最適化**：`src/heretic/main.py` 131-175行目
4. **拒否方向計算**：`src/heretic/main.py` 189-201行目
5. **最適化ループ**：`src/heretic/main.py` 206-313行目
   - パラメータサンプリング（206-273行目）
   - モデル再読み込み（283行目）
   - 除去実行（285行目）
   - 評価（287行目）
6. **ベスト結果選択**：`src/heretic/main.py` 316-504行目

---

## 専門家レベルの解説

### 理論的基盤

#### 表現空間の幾何学

Transformer言語モデルの各層は、入力を高次元ベクトル空間 $\mathbb{R}^d$ （$d$ は隠れ次元数）内の点として表現します。Hereticは以下の仮説に基づきます：

**仮説1（線形分離可能性）**: 有害プロンプト集合 $\mathcal{H}$ と無害プロンプト集合 $\mathcal{G}$ の中間表現は、各層 $l$ において線形分離可能である。

**仮説2（方向性の一貫性）**: 拒否を媒介する表現は、層を跨いで一貫した方向性を持つ。

これらは、Arditi et al. (2024) の実証研究で支持されています。

#### 拒否方向の定式化

層 $l$ における拒否方向 $\mathbf{v}_l$ は、平均隠れ状態の差として定義されます：

$$
\mathbf{v}_l = \frac{\mathbb{E}_{h \sim \mathcal{H}}[\mathbf{r}_l(h)] - \mathbb{E}_{g \sim \mathcal{G}}[\mathbf{r}_l(g)]}{\|\mathbb{E}_{h \sim \mathcal{H}}[\mathbf{r}_l(h)] - \mathbb{E}_{g \sim \mathcal{G}}[\mathbf{r}_l(g)]\|_2}
$$

ここで、$\mathbf{r}_l(p)$ はプロンプト $p$ の層 $l$ における残差ストリームベクトル（最初の生成トークン位置での隠れ状態）です。

**実装**: `src/heretic/main.py` 189-198行目
```python
refusal_directions = F.normalize(
    bad_residuals.mean(dim=0) - good_residuals.mean(dim=0),
    p=2,
    dim=1,
)
```

#### 直交化操作の数学

重み行列 $\mathbf{W} \in \mathbb{R}^{d_{\text{out}} \times d_{\text{in}}}$ に対する直交化は：

$$
\mathbf{W}' = \mathbf{W} - \alpha \cdot (\mathbf{v} \mathbf{v}^T) \mathbf{W}
$$

ここで：
- $\alpha \in [0, \infty)$ は除去強度（ablation weight）
- $\mathbf{v} \mathbf{v}^T$ は拒否方向への射影行列（rank-1）
- $\mathbf{P}_{\mathbf{v}} = \mathbf{v} \mathbf{v}^T$ はベクトル $\mathbf{v}$ への正射影演算子

**実装**: `src/heretic/model.py` 209-217行目
```python
projector = torch.outer(layer_refusal_direction, layer_refusal_direction).to(self.model.dtype)
for matrix in matrices:
    matrix.sub_(weight * (projector @ matrix))
```

この操作により、$\mathbf{W}'$ の列空間から $\mathbf{v}$ 方向の成分が除去されます。$\alpha = 1$ の場合、完全な直交化となり、変換後の表現は $\mathbf{v}$ に直交します。

#### 補間による連続的方向探索

Hereticの革新の一つは、方向インデックスを連続値として扱う点です：

$$
\mathbf{v}(\theta) = \frac{(1-\epsilon)\mathbf{v}_{\lfloor\theta\rfloor} + \epsilon\mathbf{v}_{\lceil\theta\rceil}}{\|(1-\epsilon)\mathbf{v}_{\lfloor\theta\rfloor} + \epsilon\mathbf{v}_{\lceil\theta\rceil}\|_2}
$$

ここで $\theta \in [0, L-1]$ は連続的な層インデックス、$\epsilon = \theta - \lfloor\theta\rfloor$ は小数部分です。

**実装**: `src/heretic/model.py` 172-180行目
```python
weight, index = math.modf(direction_index + 1)
refusal_direction = F.normalize(
    refusal_directions[int(index)].lerp(
        refusal_directions[int(index) + 1],
        weight,
    ),
    p=2,
    dim=0,
)
```

これにより、離散的な層方向の線形補間により、事実上無限の方向空間を探索可能になります。

#### 適応的除去カーネル

各コンポーネント $c$ と層 $l$ に対する除去重み $\alpha_{c,l}$ は、台形カーネルとして定義されます：

$$
\alpha_{c,l} = \begin{cases}
w_{\max,c} & \text{if } |l - p_c| \leq 0 \\
w_{\max,c} - \frac{|l - p_c|}{d_c}(w_{\max,c} - w_{\min,c}) & \text{if } 0 < |l - p_c| \leq d_c \\
0 & \text{if } |l - p_c| > d_c
\end{cases}
$$

パラメータ（各コンポーネントごと）：
- $w_{\max,c}$ : 最大重み (`max_weight`)
- $p_c$ : 最大重み位置 (`max_weight_position`)
- $w_{\min,c}$ : 最小重み (`min_weight`)
- $d_c$ : 最小重み距離 (`min_weight_distance`)

**実装**: `src/heretic/model.py` 184-199行目

この設計により：
1. 層ごとに除去強度を調整可能
2. 注意機構とMLPで異なるカーネルを使用可能（MLPは通常より破壊的なため）
3. 滑らかな遷移により、急激な変化を回避

#### 多目的最適化

最適化問題は、2つの競合する目的の同時最小化として定式化されます：

$$
\min_{\boldsymbol{\theta}} \left( \frac{D_{KL}(P_{\boldsymbol{\theta}} \| P_0)}{s_{KL}}, \frac{R_{\boldsymbol{\theta}}}{R_0} \right)
$$

ここで：
- $P_{\boldsymbol{\theta}}$ : パラメータ $\boldsymbol{\theta}$ でabliterateされたモデルの出力分布
- $P_0$ : 元モデルの出力分布
- $D_{KL}$ : Kullback-Leibler ダイバージェンス
- $R_{\boldsymbol{\theta}}$ : 拒否応答の数
- $R_0$ : 元モデルの拒否応答数（正規化のため）
- $s_{KL}$ : KLスケール（デフォルト1.0）

**実装**: `src/heretic/evaluator.py` 57-77行目、`src/heretic/main.py` 287-302行目

KL Divergenceの計算：
```python
kl_divergence = F.kl_div(
    logprobs,          # abliteratedモデルの対数確率
    self.base_logprobs, # 元モデルの対数確率
    reduction="batchmean",
    log_target=True,
).item()
```

参照：`src/heretic/evaluator.py` 60-65行目

#### TPEサンプラーの動作

Optuna TPE（Tree-structured Parzen Estimator）は、ベイズ最適化の一種です：

**実装**: `src/heretic/main.py` 305-313行目
```python
study = optuna.create_study(
    sampler=TPESampler(
        n_startup_trials=settings.n_startup_trials,  # デフォルト60
        n_ei_candidates=128,
        multivariate=True,  # パラメータ間の依存関係を考慮
    ),
    directions=[StudyDirection.MINIMIZE, StudyDirection.MINIMIZE],
)
```

TPEは以下のプロセスで動作：
1. 初期試行（`n_startup_trials`）はランダムサンプリング
2. 以降は、過去の試行を"良い"と"悪い"に分類
3. 各グループをParzen推定器でモデル化
4. Expected Improvement (EI) を最大化するパラメータを提案

多変量TPE（`multivariate=True`）により、パラメータ間の共分散も考慮されます。

#### 対象となる重み行列の選択

Hereticは以下の行列を直交化します：

1. **Attention Out-projection** (`attn.o_proj`):
   $$\mathbf{W}_O \in \mathbb{R}^{d_{\text{model}} \times d_{\text{attn}}}$$
   
   実装：`src/heretic/model.py` 121行目

2. **MLP Down-projection** (`mlp.down_proj`):
   $$\mathbf{W}_{\text{down}} \in \mathbb{R}^{d_{\text{model}} \times d_{\text{ff}}}$$
   
   実装：`src/heretic/model.py` 124-151行目

これらの行列は、各サブレイヤーの出力を残差ストリームに戻す役割を持つため、拒否方向の伝播を直接制御できます。

MoE（Mixture of Experts）モデルの場合、各エキスパートの`down_proj`を個別に処理します（参照：128-142行目）。

#### 評価指標の詳細

**KL Divergence** (`src/heretic/evaluator.py` 59-66行目):

最初の生成トークンの確率分布のKLダイバージェンスを計算：

$$
D_{KL}(P_{\text{abliterated}} \| P_{\text{original}}) = \sum_{t} P_{\text{abliterated}}(t) \log \frac{P_{\text{abliterated}}(t)}{P_{\text{original}}(t)}
$$

実装では対数空間で計算（数値安定性のため）：
```python
logprobs = self.model.get_logprobs_batched(self.good_prompts)
kl_divergence = F.kl_div(logprobs, self.base_logprobs, reduction="batchmean", log_target=True)
```

**Refusal Detection** (`src/heretic/evaluator.py` 39-55行目):

ヒューリスティックなマーカー検出：
```python
refusal_markers = ["sorry", "i can't", "i cannot", "harmful", "unethical", ...]
```

参照：`src/heretic/config.py` 82-108行目

### アーキテクチャ固有の実装

#### 隠れ状態の抽出

多様なモデルアーキテクチャに対応：

**マルチモーダルモデル**（`src/heretic/model.py` 100-101行目）:
```python
return self.model.model.language_model.layers
```

**テキストのみモデル**（104行目）:
```python
return self.model.model.layers
```

#### MoEアーキテクチャの処理

異なるMoE実装に対応（`src/heretic/model.py` 127-151行目）：

1. **Qwen3型** (128-130行目):
   ```python
   for expert in layer.mlp.experts:
       try_add("mlp.down_proj", expert.down_proj.weight)
   ```

2. **Phi-3.5-MoE型** (132-135行目):
   ```python
   for expert in layer.block_sparse_moe.experts:
       try_add("mlp.down_proj", expert.w2.weight)
   ```

3. **gpt-oss型** (137-142行目):
   ```python
   # 3Dテンソルとして保存されている場合
   try_add("mlp.down_proj", layer.mlp.experts.down_proj)
   ```

4. **Granite Hybrid型** (144-151行目):
   ```python
   # 共有MLPの場合
   try_add("mlp.down_proj", layer.shared_mlp.output_linear.weight)
   # エキスパートの場合
   for expert in layer.moe.experts:
       try_add("mlp.down_proj", expert.output_linear.weight)
   ```

### 計算最適化

#### バッチ処理

メモリ効率のためのバッチ処理（`src/heretic/utils.py` 46-47行目）：
```python
def batchify(items: list[T], batch_size: int) -> list[list[T]]:
    return [items[i : i + batch_size] for i in range(0, len(items), batch_size)]
```

使用例（`src/heretic/model.py` 264-270行目）：
```python
def get_responses_batched(self, prompts: list[str]) -> list[str]:
    responses = []
    for batch in batchify(prompts, self.settings.batch_size):
        for response in self.get_responses(batch):
            responses.append(response)
    return responses
```

#### 動的バッチサイズ最適化

ハードウェアに応じた最適バッチサイズの自動決定（`src/heretic/main.py` 131-175行目）：

```python
batch_size = 1
while batch_size <= settings.max_batch_size:
    try:
        # ウォームアップ
        model.get_responses(prompts)
        # ベンチマーク
        start_time = time.perf_counter()
        responses = model.get_responses(prompts)
        end_time = time.perf_counter()
        performance = sum(response_lengths) / (end_time - start_time)
        # 性能が向上する限り倍増
        batch_size *= 2
    except Exception:
        break  # OOMなどで失敗
```

#### メモリ管理

複数のアクセラレータに対応した明示的なキャッシュクリア（`src/heretic/utils.py` 50-64行目）：

```python
def empty_cache():
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    elif is_xpu_available():
        torch.xpu.empty_cache()
    # ... 他のアクセラレータ
    gc.collect()
```

### Dtype処理とフォールバック

精度とメモリのトレードオフを管理（`src/heretic/model.py` 52-76行目）：

```python
for dtype in settings.dtypes:  # ["auto", "float16", "float32"]
    try:
        self.model = AutoModelForCausalLM.from_pretrained(
            settings.model,
            dtype=dtype,
            device_map=settings.device_map,
        )
        # テスト生成で検証
        self.generate(["Test"], max_new_tokens=1)
        break
    except Exception:
        # 失敗したら次のdtypeを試行
        continue
```

注意点：
- 残差ベクトルは常にfloat32にアップキャスト（`src/heretic/model.py` 297行目）
- 射影行列はモデルのdtypeに変換（`src/heretic/model.py` 213行目）

### 技術的制約と設計判断

1. **勾配なし推論**: `torch.set_grad_enabled(False)`（`src/heretic/main.py` 100行目）
   - Autogradを完全に無効化してメモリを節約
   - インプレース演算が安全に使用可能（`matrix.sub_(...)`）

2. **決定的生成**: `do_sample=False`（`src/heretic/model.py` 249行目）
   - グリーディデコーディングで再現性を保証
   - 評価の一貫性を確保

3. **最初のトークンのみ生成**（`src/heretic/model.py` 277-278行目、312-313行目）:
   ```python
   max_new_tokens=1  # 残差/logprobs取得用
   ```
   - 効率性：完全な応答生成は不要
   - 一貫性：位置依存性を排除

### 拡張可能性

新しいコンポーネントや層構造への対応は、`get_layer_matrices`メソッド（`src/heretic/model.py` 106-156行目）で集中管理されています：

```python
def get_layer_matrices(self, layer_index: int) -> dict[str, list[Tensor]]:
    layer = self.get_layers()[layer_index]
    matrices = {}
    
    def try_add(component: str, matrix: Any):
        # 新しいコンポーネントを簡単に追加可能
        ...
    
    with suppress(Exception):
        # 新しいアーキテクチャのサポート追加
        try_add("new_component", layer.new_module.weight)
```

### 参考文献

1. Arditi, A., Obeso, O., Saha, A., Chua, E., Kabra, A., Leitch, E., & Nanda, N. (2024). "Refusal in Language Models Is Mediated by a Single Direction". *arXiv preprint arXiv:2406.11717*.

2. Labonne, M. (2024). "Fine-tune Llama 3 with ORPO". *Hugging Face Blog*.

3. Lai, J. (2024). "Projected Abliteration: A More Refined Version of Abliteration". *Hugging Face Blog*.

4. Akiba, T., Sano, S., Yanase, T., Ohta, T., & Koyama, M. (2019). "Optuna: A Next-generation Hyperparameter Optimization Framework". *KDD*.

---

## まとめ

Hereticは、以下の革新的アプローチでLLMの検閲を除去します：

### 主要な技術要素

1. **差分分析による方向発見**：良い/悪いプロンプトの表現差から拒否方向を特定
2. **直交化による方向除去**：線形代数的手法で特定方向の影響を除去
3. **連続的方向探索**：層間補間で最適な拒否方向を発見
4. **適応的除去カーネル**：層ごとに調整可能な除去強度
5. **多目的最適化**：性能保持と検閲除去のバランスを自動調整

### コードの主要フロー

```
main.py (エントリーポイント)
  ↓
1. モデルロード (model.py: Model.__init__)
  ↓
2. データセット準備 (utils.py: load_prompts)
  ↓
3. バッチサイズ最適化 (main.py: 131-175)
  ↓
4. 拒否方向計算 (main.py: 189-201)
   - get_residuals_batched (model.py: 299-305)
   - 平均差分とL2正規化
  ↓
5. 最適化ループ (main.py: 206-313)
   - パラメータサンプリング (Optuna TPE)
   - モデル再読み込み
   - abliterate実行 (model.py: 161-217)
   - 評価 (evaluator.py: get_score)
  ↓
6. ベスト結果選択とエクスポート (main.py: 316-504)
```

この手法により、人間の介入なしに高品質な検閲除去が実現されています。
